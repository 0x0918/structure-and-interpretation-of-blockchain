# 以太坊共识

Ethash是以太坊目前使用的共识算法，其前身是`Dagger-Hashimoto`算法，但是进行了很大的改动。比特币的挖矿算法随着比特币的发展出现了一些问题，比如挖矿越来越专业化，算力过于集中，出现了挖矿专用芯片，违反了`one cpu on vote`的原则 。针对比特币挖矿算法只需要计算，很容易专业化的特点，以太坊设计了一套对普通计算机相对友好的挖矿算法，增加了内存要求这一要素，提出了Dagger-Hashimoto算法。

## Dagger-Hashimoto
采用Dagger-Hashimoto算法是想要达到如下目标；
- 对抗ASIC专业矿机，避免算力集中化；
- 支持轻客户端，对硬件性能比较差的轻节点也能进行SPV验证；
- 全链存储数据；

Dagger-Hashimoto算法由Dagger和Hashimoto融合而成；

### Hashimoto
Hashimoto算法由Thaddeus Dryja发明，通过增加对内存读取瓶颈来抵制ASIC矿机，ASIC通过设计专用电路来提升计算速度。

## Dagger
Dagger算法由Vitalik Buterin发明，旨在通过DAG（有向无环图）来同时获得“memory-hard计算”和“memory-easy验证”这两个特性，其主要原理是针对每一个单独的nonce只需要访问数据集中的一小部分数据。

### Ethash
Ethash算法的总体思路是这样的，轻节点因为硬件设备和节点特性，存在计算能力不足，内存小的特点，而矿工因为挖矿需要计算大量哈希，甚至是专业设计的ASIC矿机，具有计算能力强，内存大的特点，为了对抗ASIC矿机就需要在挖矿时增加内存消耗，而验证时只需要很小的内存，避免了挖矿只需要算力的问题，使挖矿更贴近普通计算机，实践`one cpu one vote`。
> 这里可能会有疑问，既然是专业设计的矿机，为什么不可以针对Ethash算法设计计算能力强内存大的专业矿机？相较于提升计算能力，提升内存容量需要更高的成本和门槛，提升完内存之后，内存与cpu的带宽又会极大的限制内存的读取速度，而内存带宽又是很难提升的，这些限制导致设计针对Ethash算法的矿机困难重重。

Ethash算法流程；
- 根据区块信息生成一个种子（seed）;
- 根据seed计算出一个16M的伪随机cache，由轻客户端存储；
- 根据cache计算出一个1G的dataset，其中的每一个数据都是通过cache中的一小部分数据计算出来，该dataset由全节点存储，大小随时间线性增长；
- 矿工会从dataset中随机取出数据计算hash，来判断是否满足挖矿难度；
- 轻节点验证者会根据cache重新生成dataset中所需要的那部分数据，因此只需要存储cache即可；

> dataset又被称为DAG

![](https://github.com/Ice-Storm/structure-and-interpretation-of-blockchain/blob/master/img/chapter_7/6_1.png?raw=true)


具体实现；

- 在以太坊中，每30000个区块称作一个`纪元（epoch）`，每产生一个纪元就更新一次dataset和cache。

- 前2048个纪元的生成的dataset和cache的大小是硬编码在代码里的，如果超过这个数量就需要自己计算了。

    1. dataset的计算方式(2^24 + 2^17 * epoch - 128)，用这个值除以128看结果是否是一个质数，如果不是，减去128再重新计算，直到找到最大的质数为止。

    2. cache的计算方式(2^24 + 2^17 * epoch - 64)，用这个值除以64看结果是否是一个质数，如果不是，减去64再重新计算，直到找到最大的质数为止。

> dataset从1GB 开始，以每年约 520MB 的速度增大，cache从16MB 开始，以每年约 12MB 的速度增大。

Ethash是一种“memory-hard计算”和“memory-easy验证”的哈希算法，通过内存访问速度的瓶颈抵抗ASIC矿机，同时利用两级数据集实现挖矿和轻客户端验证的分离。

在介绍以太坊具体实现的时候，先介绍一下以太坊挖矿用到的FNV哈希算法。

### FNV哈希算法
FNV哈希算法全名为Fowler-Noll-Vo，是以三位发明人Glenn Fowler，Landon Curt Noll，Phong Vo的名字来命名的，最早在1991年提出。
FNV算法有三个版本：FNV-0（已废弃）、FNV-1和FNV-1a，两个算法需要用到的变量如下；
```
hash值：一个n位的unsigned int型hash值
offset_basis：初始的哈希值
FNV_prime：FNV用于散列的质数
octet_of_data：8位数据（即一个字节）
```

FNV-1和FNV-1a的算法都很简单，FNV-1算法如下
```
hash = offset_basis
for each octet_of_data to be hashed
    hash = hash * FNV_prime
    hash = hash xor octet_of_data
return hash
```

FNV-1a算法如下；
```
hash = offset_basis 
for each octet_of_data to be hashed
    hash = hash xor octet_of_data
    hash = hash * FNV_prime
return hash
```
FNV_prime的取值: 
32 bit FNV_prime = 2^24 + 2^8 + 0x93 = 16777619
64 bit FNV_prime = 2^40 + 2^8 + 0xb3 = 1099511628211

> 以太坊采用的是FNV-1


### 以太坊实现

![](https://github.com/Ice-Storm/structure-and-interpretation-of-blockchain/blob/master/img/chapter_7/6_2.jpg?raw=true)


- 首先将header和nonce合并成一个40Bytes长的数组，取它的SHA-512哈希值，作为seed，长度为64Bytes;

- 将seed转换成uint32类型的数组mix[]uint32，一个uint32数等于4Bytes，mix数组的长度为32，通过如下算法填充mix

```

mix := make([]uint32, mixBytes/4)

for i := 0; i < len(mix); i++ {

  mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])

}

将seed转换为小端序放入mix

```

- 接着通过FNV算法混淆mix数组中的每一个元素；

```

 for i := 0; i < loopAccesses; i++ {

    parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows

    for j := uint32(0); j < mixBytes/hashBytes; j++ {

        copy(temp[j*hashWords:], lookup(2*parent+j))

    }

    fnvHash(mix, temp)

}

```

- 混淆完成后通过FNV算法将mix折叠到原来的1/4；

```

for i := 0; i < len(mix); i += 4 {

    mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])

}

mix = mix[:len(mix)/4]

```

- 最后，将折叠后的 mix[]uint32 由长度为8的uint32 型数组直接转化成一个长度32的 byte 数组，这就是返回值 digest；同时将之前的 seed[] 数组与 digest 合并再取一次 SHA-256 哈希值，得到的长度32的 byte 数组，即返回值 result。

```

digest := make([]byte, common.HashLength)

 for i, val := range mix {

  binary.LittleEndian.PutUint32(digest[i*4:], val)

 }

 return digest, crypto.Keccak256(append(seed, digest...))

```



hashimoto 返回两个长度均为32的 byte 数组 digest 和 result，前文已提到，在 Ethash 的 mine 方法里，挖矿时需要经过一个死循环，直到找到一个 nonce，使得 hashimoto 返回的 result 和 target 是相等的，这时就表示符合要求。



其中的数据流如下图所示；

![](https://github.com/Ice-Storm/structure-and-interpretation-of-blockchain/blob/master/img/chapter_7/6_3.png?raw=true)


### 以太坊挖矿难度调整

以太坊的每个区块都有可能调整挖矿难度，

本区块难度 = 父区块难度 + 难度调整 + 难度炸弹

难度调整 = 父区块难度 // 2048 * MAX(1 - (block_timestamp - parent_timestamp) // 10, -99)

难度炸弹 = INT(2**((block_number // 100000) - 2))

轻节点验证
```

func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) {

 // Calculate the number of theoretical rows (we use one buffer nonetheless)

 rows := uint32(size / mixBytes)


 // Combine header+nonce into a 64 byte seed

 seed := make([]byte, 40)

 copy(seed, hash)

 binary.LittleEndian.PutUint64(seed[32:], nonce)



 seed = crypto.Keccak512(seed)

 seedHead := binary.LittleEndian.Uint32(seed)



 // Start the mix with replicated seed

 mix := make([]uint32, mixBytes/4)

 for i := 0; i < len(mix); i++ {

  mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])

 }

 // Mix in random dataset nodes

 temp := make([]uint32, len(mix))



 for i := 0; i < loopAccesses; i++ {

  parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows

  for j := uint32(0); j < mixBytes/hashBytes; j++ {

   copy(temp[j*hashWords:], lookup(2*parent+j))

  }

  fnvHash(mix, temp)

 }

 // Compress mix

 for i := 0; i < len(mix); i += 4 {

  mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])

 }

 mix = mix[:len(mix)/4]



 digest := make([]byte, common.HashLength)

 for i, val := range mix {

  binary.LittleEndian.PutUint32(digest[i*4:], val)

 }

 return digest, crypto.Keccak256(append(seed, digest...))

}

```
